Main scenario

What if AI made life easier while quietly concentrating power in corporate hands?

By 2026, AI systems become indispensable: planning, writing, and chatting like friends and colleagues. Public scepticism fades. China lags due to hardware constraints, while Europe stalls amid internal divides. By 2027, deepfake crises push the U.S. toward restricting open models. Investors demand closed systems, and a few dominant firms consolidate control. AI becomes the interface for daily life, and society splits: Some see progress, others a loss of agency.

By 2029, scenario ending, The agent economy asks: what if tireless digital workers power growth but leave labour and ethics behind? Whereas silicon blackmail asks: what if a handful of firms control AI so completely they can’t be challenged, even by governments?
Baseline assumptions for this scenario

    AI agents become highly capable but still need human oversight: Letting AI systems ‘think’ for longer enables specialised agents that transform entire sectors—from coding to finance to drug discovery. These systems can execute complex, multi-step workflows based on human-set objectives, dramatically boosting productivity. However, they aren’t perfectly reliable, so humans remain essential partners rather than obsolete bystanders.
    Computing power becomes the key that unlocks progress: Access to computational resources becomes the primary factor determining AI capabilities. The US maintains control over critical semiconductor supply chains, giving American AI companies preferential access to the most powerful computing clusters. Despite heavy investment, China cannot fully overcome export restrictions, nor match American AI capabilities.
    Open-source AI faces growing restrictions: As AI agents proliferate in sensitive areas like finance and cybersecurity, the risks of freely downloadable models become impossible to ignore. Liability concerns and venture capital pressure lead to strict limitations on advanced open-source AI, pushing developers to keep their most capable systems behind closed doors.
    A handful of giants dominate: The billions required for training frontier models create insurmountable barriers for newcomers. But it’s not just about money—incumbent American AI companies leverage their control over chips, cloud infrastructure, data partnerships, and distribution channels to capture both enterprise and consumer markets. Network effects in AI marketplaces reinforce their dominance, leaving a small oligopoly to set the terms for the global AI economy.

For more context on why these scenario assumptions may materialise, see Context: Current AI trends and uncertainties.
Mid 2025 – early 2026

By mid-2025, leading American AI companies unveil a new generation of reasoning models. These systems combine deep deliberation with intuitive capabilities—thinking for longer only when necessary. This breakthrough enables the first wave of autonomous digital agents capable of navigating online environments without much human oversight.

While early versions have limitations, their performance improves rapidly. By late 2025, agents begin entering real-world workflows. Adoption spreads across industries—not because of sudden technical leaps, but because systems are finally getting reliable enough. Tech-savvy real estate firms deploy agents for property analysis and personalised listings. In finance, complex risk assessments are automated. In less-regulated regions, healthcare providers use agents to assist with diagnostics. AI agents are no longer just tools—they’re gradually becoming knowledge workers.

Not all regions advance equally. Chinese AI companies struggle to maintain their early-2025 momentum due to export controls on state-of-the-art AI chips. Experiments slow, synthetic data pipelines falter, and customer demand outpaces what domestic firms can deliver.

Beijing responds with heavy investment in domestic AI and semiconductor industries, but stops short of triggering a full-blown arms race. AI agents, while economically transformative, are not yet militarily decisive—and both blocs recognise the bureaucratic and institutional challenges of government adoption.

In Europe, ambitions to build a sovereign AI ecosystem are stalled by politics and bureaucratic delay. Member states clash over where to build the proposed Gigafactories, while permitting issues slow data centre construction.

Meanwhile, in the U.S., the AI sector enters a new phase of hyper-competition. Three companies remain neck-and-neck, with two others in close pursuit. Top researchers are lured with compensation packages worth tens of millions, and as they move between firms, algorithmic secrets begin to diffuse across the industry.

With internet-scale training data drying up, companies pivot toward harvesting high-quality, agentic user data. Consumers are offered deep discounts in exchange for sharing interactions—feeding the training pipelines for the next generation of agents. The race is no longer just about algorithms—it’s about distribution, integration, and user data.

To gain an edge, companies begin relying more and more on their own agents internally. AI systems speed up engineering, which has become the key bottleneck in coordinating massive distributed training runs across hundreds of thousands of GPUs. While original scientific research remains out of reach, agent-assisted R&D delivers a 50% acceleration in progress compared to 2024-era systems.

Investors eyeing the agent market—especially in enterprise software—begin urging the leading American open-source company, OmniAI, to lock down their frontier models. “You’re leaving money on the table,” they argue. Leadership resists, betting that openness will win long-term through developer network effects. But tensions are growing.

At the same time, public perception of AI is shifting. Once compared to crypto fads, AI is now seen as a foundational platform. Chatbots and agents become standard across industries, and a new kind of productivity inequality emerges: those comfortable with AI accelerate, those without fall behind.

Most people encounter agents through customer support or scheduling tools nowadays. A growing minority form emotional bonds with their AI companions. And though the full economic gains haven’t yet shown up in the data, there’s a clear sense that society is undergoing a technological phase shift.
Early 2026 – early 2027

In early 2026, FrontierAI, the leading developer, launches its next-generation AI agent. Faster, more reliable, and deeply integrated into consumer devices, it earns rapid adoption for everyday tasks—managing groceries, coordinating schedules, curating personalised content. Agents are no longer niche—they’re becoming ambient assistants, embedded in daily life.

Soon after, OmniAI releases its own upgraded agent. But the rollout disappoints. Performance lags behind closed-source competitors, and under pressure from investors, the company reverses its long-standing position: it will now commercialise its frontier models and open-source only smaller, older versions. The shift sends shockwaves through the open-source community. Some see it as pragmatic. Others call it a betrayal.

Simultaneously, open-weight models become implicated in a wave of deepfake incidents, including fabrications targeting the President and key allies. The White House begins reconsidering the risks of open-source AI, especially at frontier scales. Behind closed doors, executives from major AI labs— including OmniAI— press their case to the President: releasing model weights, they warn, makes powerful tools available to anyone—with no safeguards.

Despite accusations of opportunistic regulatory capture, the administration begins drafting legislation to restrict the release of high-capability open-weight models. Senior officials invoke the need to defend American national security. Leaks about the plan spark outrage in Europe, where policymakers and researchers worry they’re being locked out of critical decisions—especially after years of investment in open-source strategies to counterbalance U.S. tech dominance.

Meanwhile, several U.S. AI companies walk back their earlier commitments to ad-free services. Critics accuse them of selling out—but the shift to monetisation brings results. Two firms introduce AI video calls with customisable digital humans, designed to be engaging, empathetic, and flattering. These personalities become especially popular among younger users, some of whom begin preferring their AI companions to real relationships.

Psychologists report growing cases of AI attachment and social withdrawal, creating family tensions and new therapeutic challenges. Yet despite rising concerns about privacy and emotional dependency, user numbers keep climbing. With agents deeply embedded in services people rely on, competition becomes harder, not easier. Switching costs rise. Platforms entrench.

Security concerns extend beyond open-source models. Closed labs, too, struggle to prevent misuse—particularly among web-browsing agents. Attackers discover ways to plant camouflaged instructions in websites, causing agents to misbehave or leak information. No fundamental fix exists. As a stopgap, companies implement multi-layered oversight, where smaller models monitor primary agents in real time and intervene when necessary. It’s inelegant, but mostly effective—and enough to satisfy compliance checks under the EU AI Act.

Although official economic metrics have yet to reflect major productivity gains, the sense of technological transition is unmistakable. In offices, homes, and classrooms, agents are becoming normalised. Media coverage begins shifting from utopian hype to more tangible questions: Will these tools exacerbate inequality? Who really controls them? What happens to work?

Financial analysts now forecast that the Big Five AI firms could effectively double their top-line within the next few years, driven by subscription access and metered inference credits. Soaring demand for inference compute drives up chip prices. In response, cloud providers and hyperscalers begin developing proprietary AI chips, reducing reliance on third-party suppliers and tightening vertical integration.

By early 2027, the divide is clear. The U.S. is pulling ahead. Chinese AI firms, still hamstrung by hardware restrictions, lag more than a year behind. Europe is politically committed to sovereignty but faces strong headwinds in infrastructure, capital and talent concentration.
Diplomacy

International cooperation emerges to govern AI development after safety concerns and high-profile incidents.
scenario-3-side-image
Diplomacy
Arms race

The US and China compete intensely for AI supremacy, treating it as a critical national security asset.
scenario-4-side-image
Arms race
Take-off

AI systems begin improving themselves at an accelerating pace, eventually operating beyond human oversight.
scenario-5-side-image
Take-off
Context: Current AI trends and uncertainties

This section outlines the technical, social and geopolitical trends and developments underlying our scenarios. It presents the key trends,

The agent economy (Ending A)
Early 2027 – late 2027

The United States enacts executive legislation which de facto prohibits the open release of AI models trained using more than 10²⁶ FLOP. The decision sends shockwaves through the open-source community, although there’s also a subdued sense of inevitability. By this point, no major U.S. contributors to frontier-scale AI remain outside the realm of closed, corporate labs. These highly capitalised entities have already moved far beyond: training runs from the elite AI circle are projected to exceed 10²⁸ FLOP by year’s end, pushing the boundaries of compute into entirely new territory.

Europe doubles down on openness. In direct response to the new U.S. legislation, the EU mandates that any AI models developed with public funding must be open-weight and freely accessible. A widely shared sense of digital sovereignty takes hold across the continent. The first pan-European AI Gigafactory nears completion, and the region’s leading AI firm, NimbusAI, successfully trains a massive new model on its new, European-built compute cluster.

NimbusAI’s offering is surprisingly competitive. For the first time in years, a European model is commercially viable, rivaling top-tier U.S. systems in most popular tasks. And so, NimbusAI successfully bets on monetising the rapidly growing market for sovereign AI, catering to governments, regulated industries, and privacy-conscious consumers.

Meanwhile, American tech giants’ lobbying efforts in Brussels falter. With a maturing domestic ecosystem, Europe is more willing to resist foreign pressure. One major U.S. AI firm follows through on its threat and withdraws services from the EU entirely. The other four decide to stay.
Late 2027 – late 2028

By the end of 2027, AI agents have become a defining feature of modern life. These systems now function like complete digital interns: they still require frequent guidance but can handle multi-hour-long projects with impressive competence. They’ve also read the whole internet.

Agents also begin replacing traditional apps. Instead of opening a spreadsheet or writing code, users now delegate entire tasks: drafting legal memos, running marketing campaigns, managing hiring pipelines, even negotiating contracts. A new form of digital literacy emerges—knowing how to prompt, orchestrate, and combine agents becomes as essential as email or spreadsheet skills once were.

Some multinationals launch full-scale AI-driven reorganisations, with certain firms now requiring employees to use agents for all workflows. Others still struggle with institutional inertia, and internal incentive structures prevent them from adapting quickly enough to reap the benefits.

Governments begin shifting their focus. Concerns over geopolitical AI dominance give way to policy debates on labour displacement, digital safety, and the ethics of agent autonomy. Though most governments remain slow adopters themselves, a few begin experimenting with AI-enhanced public services—deploying agents to supplement education, healthcare, and legal aid. Pilot programmes for job guarantees and agent taxation to fund retraining start to emerge.

By late 2028, many developed economies report modest but measurable increases in GDP growth, often at least partially attributed to AI. In this new agent-driven economy, winners and losers emerge along fault lines defined by adaptability. Adoption varies widely across companies, industries, and countries. Small businesses that embrace agents flourish. So do freelancers, creatives, and independent developers who understand how to leverage agent ecosystems.

But large segments of the white-collar workforce struggle—especially in roles that can be easily abstracted into workflows or delegated to agents. In some social circles, the mood is grim; in others, euphoric. People who adapt quickly find themselves starting new ventures, learning new skills, and pursuing entirely different careers.

The presence of slightly inferior open agents provides a critical alternative. Users dissatisfied with the American platforms can often switch to European or community-driven models, which offer personalisation and transparency not found in the American corporate stack.

It becomes clear that AI hasn’t just centralised power—it has reconfigured it. The age of models has given way to the age of agents. And while the playing field is far from level, it’s proving more dynamic and competitive than most had predicted just two years earlier.

Silicon blackmail (Ending B)
Early 2027 – mid 2027

In a move that sparks fierce debate, the President issues an executive order meant to turbo-charge U.S. AI research while safeguarding national security. Tucked inside is a contested clause that effectively bars cloud providers from hosting training runs for open-weight models exceeding 10²⁶ floating-point operations. The mandate claims extraterritorial reach, and compliance is enforced with the looming threat of even tighter global export controls on advanced chips.

With China already under heavy restrictions, the move hits Europe especially hard. European officials and open-source advocates denounce the measure as a form of extraterritorial overreach—one that stifles global competition and undermines the continent’s pursuit of digital sovereignty.

In response, the European Commission launches Operation AI Oversight, escalating enforcement of the AI Act, Digital Services Act, and Digital Markets Act. The crackdown includes steeper penalties, surprise audits, and expanded regulatory scrutiny. U.S. officials interpret the move as a targeted assault on American firms operating in Europe.

Tensions spike when two major U.S. companies suspend operations on the continent, citing a “hostile regulatory environment.”
Mid 2027 – late 2028

By the summer of 2027, global conversations about AI have shifted. Fears of an arms race recede, replaced by growing public anxiety over job displacement and the concentration of corporate power.

Rumours begin circulating that the Big Five— as the leading American AI firms are now often called— have developed informal non-compete understandings, quietly carving up the global market to avoid stepping on each other’s toes and to block new entrants.

Inside these companies, AI systems now manage core business operations—from compliance and legal reviews to HR and product strategy. With this AI-enhanced efficiency, firms begin spinning off new ventures, targeting high-value sectors like law, recruiting, and content creation. Entire ecosystems form around their tools, especially in social media, productivity software, and cloud infrastructure—locking in users and consolidating control over the digital economy.

The promise of self-improving AI systems has only partially materialised. While agents accelerate engineering workflows and streamline research logistics, they are not yet autonomous scientists: for instance, they lack the ability to come up with promising hypotheses. But more importantly, the Big Five aren’t prioritising raw capabilities anymore— instead, they are focused on user engagement, monetisation, and product integration.

This commercial focus, combined with immense capital requirements and ecosystem lock-in, prevents other countries from catching up. Developing sovereign AI agents isn’t just a matter of training a model—it’s about access to talent, data, compute, and platform reach. The Big Five’s dominance across cloud infrastructure, mobile operating systems, and productivity software creates enormous distribution advantages. Even countries with substantial investments in AI face uphill battles: domestic firms struggle to match not only the models, but the tightly integrated tooling and feedback loops that make agents useful in real-world settings. The result is a deeply asymmetric global landscape—technologically, economically, and politically.

By 2028, the macroeconomic effects are undeniable. The U.S. posts an one-point bump in GDP growth, while unemployment ticks upward. Economists debate the causes, but in fields like software engineering, paralegal work, and digital media, the trend is clear: AI is gradually replacing jobs.

Parents begin wondering what work will remain for their children. University computer science enrolments decline, as students question whether coding still offers a future. Desk workers across industries now rely on Big Five tools—not out of preference, but because they have no viable alternatives.

Sensing this leverage, the three American AI firms still operating in Europe ramp up lobbying efforts to weaken EU regulation. With most open-source options sidelined and Chinese systems still viewed with suspicion, European consumers and businesses are boxed in.

When the firms hint that they might withdraw entirely from the EU, the threat carries weight: such a move could cripple Europe’s economic competitiveness overnight.

Relations between Brussels and Washington plunge to new lows. Backed by key member states, the European Commission refuses to yield. “Europe will not be blackmailed,” declares one senior official. But the standoff proves costly: within weeks, U.S. firms begin pausing operations across the EU.

Brussels promises bold new investments in domestic AI, but the gap is wide and growing. For now, the continent is left scrambling to maintain essential digital infrastructure and services.

Outside the EU, financial markets soar. The American economy accelerates. Some central banks raise interest rates in an attempt to cool overheating sectors, particularly in tech and services.

But prosperity is far from evenly distributed. The primary beneficiaries are shareholders, executives, and AI-native professionals. Communities hit hard by automation are left behind. Protests erupt, driven by economic frustration and digital disenfranchisement.

Meanwhile, workers empowered by AI occupy a different social stratum—connected by code, divided by everything else.
