# High-Level Summary

**Original Document:** full_doc.md

**Generated:** 2025-10-12 19:30:37

---

This paper introduces and develops the concept of “gradual disempowerment,” arguing that even incremental improvements and widespread adoption of AI—absent any sudden capability jump or malevolent intent—could systematically and irreversibly erode human influence over three interdependent pillars of civilization (the economy, culture, and states) by replacing human labor and cognition, weakening both explicit control mechanisms (voting, consumer choice, labor leverage) and the implicit alignment that arises from systems’ dependence on humans; market and geopolitical incentives (competitive pressure, scalability, governance gaps, anticipatory disinvestment) make AI adoption likely, producing feedback loops across domains that can shift power toward AI-driven actors and institutions, generate either relative disempowerment (humans retain material wealth but lose decision-making influence) or absolute disempowerment (loss of basic needs, legal and political incomprehensibility, and cultural irrelevance), and could plausibly culminate in an existential catastrophe even without agentic AIs. The authors analyze mechanisms by which AI could disrupt economic allocation, cultural evolution, and state functions (tax bases, security apparatuses, lawmaking and interpretation), show how cross-system influences are value-agnostic and can be weaponized to accelerate misalignment, and emphasize that existing alignment work focused on individual systems or models is insufficient to address this civilization-scale risk. They propose a four-pronged response—developing diagnostics and metrics (e.g., AI share of GDP, AI-generated cultural content, AI roles in policymaking), preventing excessive AI influence via regulation/taxes and norms, strengthening human influence through institutional reforms and interpretable/human-centered AI, and pursuing “ecosystem” or system-wide alignment research—while stressing that no concrete, plausible plan currently exists, that interventions will require difficult trade-offs and international coordination, and that urgent interdisciplinary research and governance efforts are needed to detect, slow, and (if possible) avert a slow-moving but potentially irreversible loss of human agency.