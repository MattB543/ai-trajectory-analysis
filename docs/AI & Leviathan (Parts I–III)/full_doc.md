# AI and Leviathan: Part I

_The institutional economics of an intelligence explosion_

**Author:** Samuel Hammond
**Published:** August 23, 2023
**URL:** https://www.secondbest.ca/p/ai-and-leviathan-part-i

---

Imagine a breakthrough happened and suddenly everyone had access to cheap, x-ray style glasses. The glasses look like normal, everyday glasses, but come with a dial setting that lets you see through walls, people's clothing, etc. It somehow works on old photos and video recordings too.

On one level, this would be amazing. You might notice the mysterious lump on your friend’s thyroid, say, catching their cancer early and saving them untold medical costs. But in the immediate term, universal and near-undetectable access to the glasses (or contact lenses, if you prefer) would be a security and privacy disaster. No one's home or device security was compromised per se. Rather, it's more like a society designed around the visible light spectrum became maladapted overnight.

There are three canonical ways that society could respond:

1. **Cultural evolution**: we embrace nudism and a variety of new, post-privacy norms;
2. **Mitigation and adaptation**: we start wearing lead underwear and scramble to retrofit our homes, office buildings, and locker rooms with impenetrable walls;
3. **Regulation and enforcement**: we ban or tightly regulate the technology and build an x-ray Leviathan for inspecting people's glasses, punishing violators, etc.

The option where everyone spontaneously coordinates to never use the glasses, or to only use them for a subset of pro-social purposes, is unstable. Even if you're a voyeur and access to the glasses benefits you personally, there's an underlying prisoner's dilemma, and so we quickly shift to the equilibrium where everyone has the glasses even if we all preferred the world without them.

The glasses are a metaphor for Artificial Intelligence.

It’s barely a metaphor. AI already unlocks a kind of x-ray vision via the [displacement of WiFi signals](https://www.vice.com/en/article/y3p7xj/scientists-are-getting-eerily-good-at-using-wifi-to-see-people-through-walls-in-detail) in a room, and with a few IR sensors you’ll eventually be able to interpolate accurate nude bodies onto every pedestrian in Times Square. The nudist AR filter won’t be allowed in the Apple VisonPro app store, but the basic technology will be sufficiently cheap and open source to make that a moot point.

## Signal extraction

AI is a microscope. **It increases the information resolution of the universe.** This has many amazing implications but also many scary one.

AI lets us [refactor legacy code](https://understandlegacycode.com/blog/can-ai-refactor-legacy-code/), [restore ancient scrolls](https://scrollprize.org/), and [detect new galaxies](https://phys.org/news/2022-07-ai-assisted-analysis-three-dimensional-galaxy-universe.html) in old astronomical surveys. At the same time, AI turns your [gait into a finger print](https://apnews.com/article/bf75dd1c26c947b7826d270a16e2658a), [a microphone into a key logger](https://arstechnica.com/gadgets/2023/08/type-softly-researchers-can-guess-keystrokes-by-sound-with-93-accuracy/), and a snapshot of your face into a [> 93% accurate polygraph test](https://link.springer.com/chapter/10.1007/978-3-031-03884-6_29).

[![](https://substackcdn.com/image/fetch/$s_!WKyg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F06730bc7-00f9-4b35-afc7-09a1e394fc99_1258x703.png)](https://substackcdn.com/image/fetch/$s_!WKyg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F06730bc7-00f9-4b35-afc7-09a1e394fc99_1258x703.png)

Jiaqi Geng et al. (2022) “[DensePose from WiFi](https://arxiv.org/abs/2301.00250)”

While deepfakes are a growing concern, AI is overall making the world radically less opaque. Perfect transparency has costs of its own. Knowledge will expand and barriers to manipulating the world will decrease. We will literally hear the cries of [stressed out flowers](https://www.nature.com/articles/d41586-023-00890-9) and have [conversations with whales](https://www.youtube.com/watch?v=N34ZK6QLWbE). Then, one day, an AI model for completing your sentences will learn to finish your thoughts, smashing the subjective divide that much of Western philosophy assumed was impenetrable.

Many of these use-cases aren’t new, but are only now getting reliable thanks to scaling. If there is signal in the noise, a big enough neural network will extract it, and in a way that’s getting exponentially cheaper and easier to access overtime. You won’t even have to `pip install`! Your Jarvis-like AI assistant will simply call up bespoke models from HuggingFace or GitHub on demand. For the DnD players out there, it will be like an amulet that grants its wearer a natural 20 on every arcana check.

This sounds liberating, and in many ways it will be. But history also suggest that enhancements to our natural liberty can be paradoxically oppressive, at least in the short run.

To be clear, what follows is not an argument for pausing AI development, even if we could. While I think we will need new oversight mechanisms for deploying frontier models safely as their [scale and power](https://epochai.org/blog/extrapolating-performance-in-language-modelling-benchmarks) ramps up, our goal should not be to stop AI but rather to in some sense [master it](https://www.politico.com/news/magazine/2023/05/08/manhattan-project-for-ai-safety-00095779).

If anything, accelerating the different modalities of defensive AI may be our best hope for making the “mitigation and adaptation” option the path of less resistance. Nevertheless, it’s important to be clear about the many ways in which our AI future is [a package deal](https://www.cato-unbound.org/2007/03/11/tyler-cowen/paradox-libertarianism/), and to draw out the implications for the likely evolution of our social order without prejudice.

## The State of Nature

Thomas Hobbes famously described life in the “state of nature” as a “war of all against all.” This is sometimes confused as a claim about hunter-gather societies, but Hobbes was actually alluding to the catastrophic conditions of the English Civil War, from which he fled for his personal safety. _[Leviathan](<https://en.wikipedia.org/wiki/Leviathan_(Hobbes*book)>)* was first published in 1651, near the start of the Interregnum. Having perceived the war’s origins in the growing fragmentation and radicalization of English society under the tenuous, personal rule of King Charles I, _Leviathan_ provided a theoretical argument for why absolute monarchy was the only way to restore peace and order. Hobbes’ notion of a social “covenant” wasn’t a [literal contract](https://iep.utm.edu/soc-cont/) that individuals signed, but rather an abstract description of the process whereby warring factions achieve a political settlement by ceding their “natural liberty” to interfere in each other’s affairs to a higher authority.

The proximate causes of the English Civil War are complex and manifold, but the macro story is one of [disruptive technological change](https://www.sciencedirect.com/science/article/abs/pii/S0014292121001641). While the printing press was invented two centuries prior, the War occurred at the inflection of the printing _revolution_ — the point of criticality that unlocked take-off growth in printed outputs. The first publication of the King James Bible was in 1611, for example, just 30 years before the war but only 55 years before the [birth of journalism](http://thehistorypress.co.uk/articles/the-english-civil-war-and-the-rise-of-journalism/) with the first regularly published English newspaper, the _[The Oxford Gazette](https://en.wikipedia.org/wiki/The_London_Gazette)_.

[![](https://substackcdn.com/image/fetch/$s_!SZTg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb02a3623-1c99-4698-b06d-c8624ab2cc6a_1432x983.png)](https://substackcdn.com/image/fetch/$s_!SZTg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb02a3623-1c99-4698-b06d-c8624ab2cc6a_1432x983.png)

Jeremiah Dittmar (2011) "[The Welfare Impact of a New Good: The Printed Book](https://www.semanticscholar.org/paper/The-Welfare-Impact-of-a-New-Good%3A-The-Printed-Book-Dittmar/939bb19e943dfc478359f74b5c7bc87c2034230a)"

Widespread access to printing enabled equally widespread dissent, spurring a “[revolt of the public](https://press.stripe.com/the-revolt-of-the-public)” that mirrored the dynamics Martin Gurri attributes to the internet era. From the English Reformation on, growing access to information thus not only broadened people’s minds to alternative [political allegiances](https://www.jstor.org/stable/25472844), but made them increasingly aware of their differently-thinking neighbors. When Parliament’s legal controls over the press [all but collapsed](https://www.jstor.org/stable/41999120?read-now=1&oauth_data=eyJlbWFpbCI6InNhbXVlbHBoYW1tb25kQGdtYWlsLmNvbSIsImluc3RpdHV0aW9uSWRzIjpbXSwicHJvdmlkZXIiOiJnb29nbGUifQ&seq=3#page_scan_tab_contents) in 1643, its episcopal licensing and censorship regime was turned over to an unregulated market, making it even easier for Puritan separatists, Independents and other radical nonconformists to find likeminded others and coordinate against the Church. The Parliament, meanwhile, was itself contesting the authority of the Crown, creating what the historian Robert Zaller called a new “[discourse of legitimacy](https://www.sup.org/books/title/?id=10148).” Over a few dizzyingly short years, ideological escalation across multiple fronts finally reached its denouement in regicide and mass violence.

AI is often compared to the printing press, but the parallels between Early Modern England and contemporary America extend beyond the technological. Our cultural and ideological schisms are intensifying; the new Puritans have run headlong into a conservative counter-reaction; and our parliamentary debates revolve around issues of censorship as the prior century’s media controls succumb to the open internet. Even the power of the U.S. Presidency has reached its nadir, as if awaiting an [originalist King](https://en.wikipedia.org/wiki/Personal_Rule) to reassert the [unitary executive](https://en.wikipedia.org/wiki/Unitary_executive_theory) and precipitate a crisis.

## Accelerating to what?

These schisms are reflected in the different AI camps. Some favor regulating AI development until we can assure perfect safety, perhaps through a licensing regime. Others wish to plow forward, accelerating access through open source.

The English reformer and “intelligencer,” [Samuel Hartlib](https://en.wikipedia.org/wiki/Samuel_Hartlib#:~:text=Hartlib%20set%20out%20with%20a,to%20modern%20internet%20search%20engines.), was the “effective accelerationist” of his day. It was his stated goal to “record all human knowledge and to make it universally available for the education of all mankind,” and he often printed technical texts to circulate at his own expense — the closest thing to open sourcing at the time. Today’s AI evangelists have similarly lofty goals, from Emad Mostaque’s mission to use AI to [educate the world’s children](https://www.youtube.com/watch?v=h-oF5dWuXAs), to Marc Andreesen’s [vision of AI](https://a16z.com/2023/06/06/ai-will-save-the-world/) as a tool for augmenting humanity across virtually every domain.

The accelerationists have the long view of history on their side, and I broadly support the Andreesen vision of the future. Nonetheless, it is always easier to imagine the end point of a technology than to foresee the trade-offs and forking paths that inevitably arise during the transition.

[George Hotz’s](https://www.youtube.com/shorts/E7jtVW6TypM) _[Chaotic Good](https://easydamus.com/chaoticgood.html)_ instinct to open source potentially dual-use models as quickly as possible has a particularly high potential for blowback. The e/acc ethic is to see open source as pulling forward the advancement of human freedom while validating a DEF CON-style [security mindset](https://security.stackexchange.com/questions/82362/in-citizenfour-what-was-edward-snowden-mitigating-with-a-head-blanket). As more of the economy flows through proprietary models, open source alternatives will also be an essential check on AI becoming monopolized by the state or a handful of tech behemoth.

Fortunately, there is huge middle ground between the safetyist’s “[FDA for AI models](https://rtp.fedsoc.org/blog/the-problem-with-ai-licensing-an-fda-for-algorithms/)” and the rapturous urge to democratize powerful new capabilities the moment the training run ends. If offensive capabilities democratize faster than adaptation and defensive technology can keep up, open source maximalism could even jeopardize the cause of freedom itself, accelerating the conditions for the AI Leviathan that Hotz and company fear most.

## Minority rule

Before 2001, [airport security](https://www.npr.org/2021/09/10/1035131619/911-travel-timeline-tsa) was almost invisible. You could even drive between Canada and the US without a passport. Then, one fateful morning in September, 19 terrorists murdered nearly 3000 people in the span of a few hours. [One week later](https://en.wikipedia.org/wiki/2001_anthrax_attacks), letters containing anthrax spores began showing up in important peoples’ mailboxes, killing five. Eight weeks after that, [Richard Reid](https://www.fbi.gov/history/artifacts/richard-reids-shoes) was caught mid-flight trying to light a bomb hidden in his shoe. Amid this rapid succession of events, our leaders suddenly realized that technology and globalization were introducing a series of _asymmetric_ risks. From bioweapons to hijackings, you now only needed a small group of extremists or a lone radical to wreak havoc across society.

Society responded in all three of the canonical ways listed above. We mitigated risks by fortifying border and airport security. We enhanced enforcement by passing the Patriot Act and funding for new forms of high-tech surveillance. And our culture quickly adapted to the growing [security theater](https://en.wikipedia.org/wiki/Security_theater), buttressed by fears of Islamic radicalism and an eruption in national solidarity.

In retrospect, we over-reacted. While terrorism loomed large psychologically, [the risks were quantifiably small](https://www.amazon.com/Risk-Science-Politics-Fear-gardner-dan/dp/1905264151) compared to the mundane things that kill people every day. In the 12 months after 9/11, for example, the increased fear of flying plausibly caused [an estimated](https://pure.mpg.de/rest/items/item_2101348/component/file_2101347/content) 1,600 excess traffic fatalities. Fear of Islamic terrorism has since subsided, but these enhanced security protocols not only remain in place, but continue to be built upon and even repurposed for [domestic threats](https://www.whitehouse.gov/briefing-room/statements-releases/2023/06/27/fact-sheet-national-strategy-for-countering-domestic-terrorism-strategic-implementation-update/).

[![](https://substackcdn.com/image/fetch/$s_!5E_C!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde2eaa21-d0ee-4af6-9b95-104f5b43b6a5_1344x896.png)](https://substackcdn.com/image/fetch/$s_!5E_C!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde2eaa21-d0ee-4af6-9b95-104f5b43b6a5_1344x896.png)

Dangerous misuse of AI will probably be similarly rare. Most people are simply not sociopaths. Nevertheless, many areas of life follow the logic of [Nassim Taleb’s Minority Rule](https://medium.com/incerto/the-most-intolerant-wins-the-dictatorship-of-the-small-minority-3f1f83ce4e15), in which a small but intolerable minority ends up setting the rule for everyone. Fewer than 2% of Americans have a peanut allergy, for example, and yet many d spaces ban foods containing peanuts just to be safe.

Depending on how the offensive-defensive balance shakes out, AI has the potential to return us to a world in which security is once again invisible. You won’t have to remove your shoes and debase yourself before a TSA agent. Instead, a camera will analyze your face as you walk into the terminal, checking it against a database of known bad guys while extracting any predictive signal hidden in your facial expressions, body language, demographic profile, and social media posts.

Airports are a bit of a special case, however. As walled gardens, airport security can leverage the benefits of vertical integration. And as gateways to faraway destinations, travelers are forced to either sign-away certain rights or take the bus. Most d spaces aren't like this. From small businesses to the public park, our daily security largely depends on the goodwill and discretion of other people. Thus, to the extent AI creates security and privacy risks _everywhere_, more and more d spaces may end up operating like an airport, i.e. like a surveillance state in miniature.

In turn, the coming [intelligence explosion](https://www.dwarkeshpatel.com/p/carl-shulman#details) puts liberal democracy on a knife edge. On one side is an AI Leviathan; a global singleton that restores order through a Chinese-style panopticon and social credit system. On the other is state collapse and political fragmentation, as our legacy institutions fail to adapt and give way to new, [AI-native organizations](https://blog.mutable.ai/p/the-ai-organization-part-i) that solve the [principal-agent problem](https://en.wikipedia.org/wiki/Principal%E2%80%93agent_problem) and unlock localized collective action at blazing speeds. This includes the fortification of privacy and security, obtained in part through an opt-in covenant to leave one’s bioweapons and x-ray glasses at the proverbial door.

Peering through the event horizon of this latter path, the contours of a new, quasi-medieval social order begin to take shape. But I’m running up against Substack’s character limit, so that will have to wait for [Part II](https://www.secondbest.ca/p/ai-and-leviathan-part-ii).

**In the meantime, enjoy this podcast I recorded with Erik Torenberg:**

# AI and Leviathan: Part II

_Preparing for regime change_

**Author:** Samuel Hammond
**Published:** August 28, 2023
**URL:** https://www.secondbest.ca/p/ai-and-leviathan-part-ii

---

_This picks up from [Part I](https://www.secondbest.ca/p/ai-and-leviathan-part-i) but can also be read standalone._

---

AI safety means different things to different people, but whether the focus is job loss or the x-risk from an unaligned superintelligence, the concerns are always presented as relatively first-order. That is, AI safety is usually conceptualized in terms of what AI will do _directly_, rather than in terms of AI’s likely indirect, second-order effects on society and the shape of our institutions. This is an enormous blind spot.

Circa the early 2000s, “internet safety” discussions revolved around first-order issues like identity theft, cybercrime and child exploitation. But with the benefit of hindsight, these direct concerns were swamped by the internet’s second-order effects on our politics and culture. Indeed, between an [information tsunami](https://press.stripe.com/the-revolt-of-the-public) and new platforms for mass mobilization, the internet destabilized political systems worldwide, even leading to [outright regime change](https://jia.sipa.columbia.edu/online-articles/internet-regime-breakdown-and-democratization-lessons-tunisia) in the case of the Arab Spring.

To the extent AI is simply the next stage in the digital revolution, I expect these trends to only intensify. The issue is not that AI and informational technology are _inherently_ destabilizing. Rather, to put it in slightly Marxian terms, the issue is that society’s technological base is shifting faster than its institutional superstructure can keep up. Populist leaders who promise to root out corruption and reset the system are a symptom of governance structures that have in some sense lost their “[direction of fit](https://en.wikipedia.org/wiki/Direction_of_fit),” like clothes that shrank in the wash or a species outside its evolutionary niche.

China’s ruling class studied the internet-enabled revolts in Cairo and Tunisia with close concern. As good historical materialists, the CCP grokked how changes in the mode of production can lead to changes in the structure of social relations. They therefore [redoubled their investment](https://thediplomat.com/2011/10/chinas-arab-spring-cyber-lessons/) in internet surveillance and other societal controls, nipping their own Jasmine Revolution in the bud.

[![](https://substackcdn.com/image/fetch/$s_!p1zk!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f9ca933-c5ab-4fcf-866f-436c618cfbe9_1344x896.png)](https://substackcdn.com/image/fetch/$s_!p1zk!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f9ca933-c5ab-4fcf-866f-436c618cfbe9_1344x896.png)

Democratized AI is a much greater regime change threat than the internet, and the CCP is treating it as such. Chinese regulators recently released [draft rules](https://techcrunch.com/2023/04/11/prohibition-of-ai-that-subverts-state-power-in-china-may-chill-its-nascent-industry/) to require user verification and security reviews for ChatGPT-like models. The rules will also prohibit “any content that subverts state power, advocates the overthrow of the socialist system, incites splitting the country or undermines national unity.”

America and the liberal democracies in the West are open societies and unlikely to ever adopt such strict controls over AI, if they could even be enforced. At the same time, we are only truly “open” at the meta-level. Private services and organizations impose any number of terms and conditions on their users, including things that would seem draconian if imposed by the state. From workplace policies and credit scores to DRM and data brokers, the liberal constitutional tradition doesn’t so much preclude invasive surveillance and social regulation as offload those functions into competing private hands.

For generations, it was an implicit assumption of U.S. foreign policy that economic liberalization and free trade would push autocratic regimes to democratize. [Information technologies](https://www.foreignaffairs.com/articles/1997-09-01/bits-bytes-and-diplomacy) that give voice to the voiceless were key to this grand strategy; a kind of _glasnost_ in a bottle. This is why the Defense Department invested so heavily in the early internet and why our international development agencies promote internet access abroad. As one [USAID report](https://www.usaid.gov/digital-development/digital-inclusion/connecting-people-transforming-nations) puts it, “Connecting People. Transforming Nations.” The idea that technology can precipitate a regime change is thus not foreign to the U.S. political establishment; they just assumed our relative openness would keep those dynamics from playing out at home.

The theory that free trade and communications technology would promote democracy [was always underspecified](https://ciaotest.cc.columbia.edu/olj/fp/fp_99sha01.html). Democracy is itself a hazy concept, a bit like clinical depression. We may know a depressed person when we see one, but brains are complex systems, so it’s quite likely that depression is actually a variety of different phenomena that get bundled according to their symptomatology. Saying “the internet promotes democracy” is thus like saying “SSRIs treat depression.” In reality, SSRIs block the reabsorption of serotonin into particular neurons, which causes a cascade of poorly understood effects that happen to include improved mood.

The effects of information technology on society are just as complex and liable to cut in different directions. While weaker states faced crises, China adapted their digital institutions to mitigate popular dissent and regulate society with [unprecedented granularity](https://en.wikipedia.org/wiki/Social_Credit_System#Examples_of_policies). Similarly, the signal extraction unlocked by AI could point to a radically more transparent society; or, at second-order, society could react to that heightened transparency by building their fences higher. In stronger states, access to AI could even become monopolized by an [all-seeing Leviathan](https://www.amazon.com/Perfect-Police-State-Undercover-Surveillance-ebook/dp/B08HLP668T), turning the democratic _telos_ of information technology on its head.

## Internalizing costs

Hobbes’ case for the _Leviathan_ ultimately rests on a kind of negative externality. The more technology empowers and emboldens the sovereign individual, the more space there is for conflict at the boundary of our intersecting spheres of influence. Wherever the negative externality to coexisting is high, one thus tends to find either civil conflict or a [draconian enforcement regime](https://www.washingtonpost.com/world/2023/05/15/bukele-gang-crackdown-salvador/) to compensate.

In medieval times, freedom simply meant the condition of not being a serf or slave, while the richer concept of liberty, to the extent it existed at all, referred to the inviolability of the great estate. It was an [inherently corporate concept](https://www.libertarianism.org/publications/essays/medieval-liberty-its-evolution); the liberty to govern your fief — the walled garden of yore. The modern, individualist conception of liberty, in contrast, emerged with the [consolidation of the modern nation-state](https://www.cato-unbound.org/2019/02/20/mark-koyama-noel-d-johnson/competition-among-states-wasnt-sufficient-religious-liberty/) and the adoption of impersonal legal institutions. These institutions were ultimately made possible by the printing revolution and the growing legibility of nature and society, but only after a bloody dialectic.

Individual rights, the rule of law, and negative liberties thus have a historical if somewhat paradoxical dependence on strong, centralized governments with high rates of fiscal and administrative capacity. This makes liberal democracy as we know it the byproduct of a contingent technological equilibrium; one that AI is almost certainly going to change.

One can think about the “industrial organization” of modern nation-states in terms of Ronald Coase’s _[Theory of the Firm](https://en.wikipedia.org/wiki/Theory_of_the_firm)_. When trust is low and transaction costs are high, it often makes sense to produce things in-house rather than contract with a third party. After all, contractors are hard to monitor and don’t always do exactly what you want, much less on time. Corporations thus exist to economize on transaction costs by integrating production within a vertical hierarchy, enabling greater monitoring and command-and-control.

[![Transaction Costs - Definition, Types, and Transaction Cost Economics](https://substackcdn.com/image/fetch/$s_!Uv5S!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9422569c-e55d-46ec-b751-7f0bd1176ef1_986x358.png "Transaction Costs - Definition, Types, and Transaction Cost Economics")](https://substackcdn.com/image/fetch/$s_!Uv5S!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9422569c-e55d-46ec-b751-7f0bd1176ef1_986x358.png)

Governments exist for similar reasons. Some things, like national defense and [basic legal institutions](https://www.cambridge.org/core/journals/economics-and-philosophy/article/abs/law-as-a-public-good-the-economics-of-anarchy/AFDCFEFADE2C6C92CFF3CEE30E08531B), are close to pure public goods. Other things, like roads and bridges, can be produced privately, but often involve so many competing interests as to make bottom-up negotiation impractical. The same goes for many kinds of market failure. Pollution externalities could, in principle, be solved by creating property rights over the air and letting rights-holders negotiate, but in practice it’s easier (read: the transaction costs are lower) to simply [tax polluters](https://www.niskanencenter.org/a-coasean-rationale-for-a-carbon-tax/) according to an estimate of the social cost of their pollution. The size and scope of liberal democracies thus grew beyond its laissez faire phase in tandem with the complexity of industrial society.

Governments and corporations also economize on transaction costs by creating universal standards and procedures. Just as courts establish common precedents and companies require their employees to use the same software, governments coordinate d time zones, units of measurement, and industry standards.

Decision makers in corporations and governments don’t necessarily understand Coase’s theory explicitly. Rather, organizations look the way they do because of some mix of intentional planning, competition and path dependency. In competitive markets, corporations that outsource excessively or insource the wrong things are less profitable than those that don’t. They thus go out of business or are reorganized from within. The competitive pressures on governments are weaker and more indirect but still exist. Democracies must continuously broker with internal stakeholders. Institutions that attract productive capital and labor tend to thrive, while grossly inefficient governments are [punished by their bond holders](https://www.amazon.com/10-Less-Democracy-Should-Elites/dp/1503603571) and forced to adopt structural reforms. If a government expands too far beyond its optimal scope, whether in policy substance or territorially, it can face a popular revolt or even disintegrate, as occurred with the American Revolution, the break-up of the Soviet Union, and past waves of [decolonization](https://en.wikipedia.org/wiki/Decolonization).

The modern nation-state is itself the product of institutional competition. Around the time of the printing revolution, the fragmented kingdoms and principalities of Europe began to vertically integrate into consolidated nation-states. They built armies, professionalized tax collection, and started threatening their neighbors with conquest and conversion, compelling those neighbors to build armies of their own. Old settlements broke down and war reigned for decades before stabilizing with the Peace of Westphalia and the mutual recognition of sovereign borders. The modern nation-state thus exists not in spite of anarchy but because of it.

I was an anarchist through my teenage years, but learned to love the state once I realized that, absent dramatic technological change, an anarchic world would quickly snap back to a world of centralized governments. While neoreactionaries and anarchocapitalists fantasize about a [patchwork system](https://www.unqualified-reservations.org/2008/11/patchwork-2-profit-strategies-for-our/) of competing, opt-in [network states](https://thenetworkstate.com/), the presence of transaction costs makes those jurisdictions vulnerable to might-makes-right conquest. In such a system, competing jurisdictions would be driven by evolutionary selection pressures to merge with their neighbors, harmonize their laws, produce public goods, and forge treaties with their remaining foes. To the extent this exactly mirrors the transition from feudalism to centralized nation-states, we are already living under a kind of anarchy — a point [Hobbes understood well](https://plato.stanford.edu/entries/realism-intl-relations/#HobbAnarStatNatu). Between the realist anarchy of the international order and the polycentricity of our domestic institutions, our contemporary anarchy is simply one that trades-off unalloyed freedom for enormous [efficiencies of scale](https://www.amazon.com/Efficient-Society-Canada-Close-Utopia/dp/0140292489).

## Anarchy unbound

The smarter anarchists know all this, and so pair their political philosophy with a kind of techno-capitalist [accelerationism](https://en.wikipedia.org/wiki/Nick_Land). Blending ‘70s counterculture with Hayek’s work on information theory, monetary economics, and [sensory cybernetics](https://cybertrophic.wordpress.com/2020/09/01/order-but-not-design-friedrich-hayek-cybernetics/), the early techno-libertarians imagined a future in which the internet, AI, and digital money would converge to bring about a radical new form of [decentralized self-government](https://www.mercatus.org/hayekprogram/research/books/anarchy-unbound).

Timothy Leary was perhaps the most prophetic on this account. In a controversial speech at the 1977 Libertarian Party Convention titled “[Terrestrial and Post-​Terrestrial Freedom](https://www.libertarianism.org/publications/essays/1977-libertarian-party-national-convention),” Leary extrapolated from the early ARPANET to “[a network that would connect computers worldwide](https://reason.com/2006/06/19/timothy-leary-the-internet-and/),” allowing real time communication and a revolution against the established order. While the audience dismissed him at the time, Leary’s prescience has since been vindicated by the growing tempo of internet-enabled revolts, from the Arab Spring and the protests in Iran, to America’s own slapdash peasant rebellion on January 6th.

From the late 1990s to the mid-2000s, techno-libertarians could be found on obscure internet forums debating superintelligence timelines, life extension technologies, and the ideal Martian system of government. They called themselves the [Extropians](https://maximumprogress.substack.com/p/grading-extropian-predictions). Among their ranks were many now-recognizable names, including AI theorists like Eliezer Yudkowsky and Nick Bostrom, cryptocurrency pioneers like Hal Finney and Nick Szabo, nanotechnologists like Eric Drexler, and would-be [brain uploads](https://ageofem.com/) like Max More and Robin Hanson.

The Extropians could both see where technology was headed and appreciated the interplay between technology and institutional evolution. [Assuming our civilization survives](https://ntrs.nasa.gov/citations/19940022856), the AI historians of the future may look back on their (often pseudonymous) treatises as a kind of singularitarian Republic of Letters.

I was born in 1991 but have been online since 1999, the year I created my first Newgrounds account from the Windows 95 in my parents’ attic. As my interests shifted from stickman animation to science and philosophy, I became acquainted with libertarian anarchists like [David Friedman](https://en.wikipedia.org/wiki/The_Machinery_of_Freedom) and futurists like Ray Kurzweil, and saw the emergence of self-regulating services like E-bay and Wikipedia as demonstrating [their productive fusion](https://www.adamsmith.org/blog/regulation-industry/uber-forms-of-governance). I thus studied as much social science as I could and, in 2015, moved from rural Canada to Washington, DC, for a graduate fellowship within the Mercatus Center’s technology program; the reputed home for rationalist libertarians, “[analytical anarchists](https://www.mercatus.org/hayekprogram/research/book-chapters/positive-political-economy-analytical-anarchism),” and even a few OG Extropians.

## The Narrow Corridor

This biographical detour is just to establish my bona fides with the e/acc world, as the heirs to the Extropians. I remain no less committed to the cause of human freedom; however, I have updated to the fragility of its institutional conditions. Political liberalism, I’ve come to realize, exists within what Acemoğlu and Robinson call “[The Narrow Corridor](https://www.amazon.com/Narrow-Corridor-States-Societies-Liberty/dp/0735224382),” a kind of harmonious saddle path for the co-evolution of state and society. [As Acemoğlu puts it](https://news.mit.edu/2019/narrow-corridor-acemoglu-liberty-0924), “You need this conflict to be balanced… If society is too weak, that leads to despotism. But on the other side, if society is too strong, that results in weak states that are unable to protect their citizens.”

[![POPULISM AND THE 'NARROW CORRIDOR' OF LIBERTY AND JUSTICE | National  Institute Economic Review | Cambridge Core](https://substackcdn.com/image/fetch/$s_!ToM1!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e2e0174-0d73-415f-90ef-9da38a3866fd_1192x1021.png "POPULISM AND THE 'NARROW CORRIDOR' OF LIBERTY AND JUSTICE | National  Institute Economic Review | Cambridge Core")](https://substackcdn.com/image/fetch/$s_!ToM1!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e2e0174-0d73-415f-90ef-9da38a3866fd_1192x1021.png)

From: “[Populism and the ‘Narrow Corridor’ of Liberty and Justice](https://www.cambridge.org/core/journals/national-institute-economic-review/article/populism-and-the-narrow-corridor-of-liberty-and-justice/74889B3017697FD29E7C2150D2283C59)” (2022)

Compare Switzerland to Afghanistan. Switzerland is a federal republic composed of 26 cantons with significant autonomy, making it one of the most decentralized countries on earth. It also routinely ranks first on various indices of freedom and human development. Afghanistan, in contrast, suffers from many geographic and cultural barriers to state formation, from hills that insurgents can escape to, to [clan-based social networks](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4200629) that inhibit inclusive institutions like the rule of law. This results in a weak state typified by the constant threat of [organized violence](https://www.econlib.org/library/Columns/y2015/Klingtwoforms.html), creating a market opportunity for the Taliban [as a provider of social order](https://items.ssrc.org/insights/how-the-taliban-justice-system-contributed-to-their-victory-in-afghanistan/) of last resort, supported in part through repressive religious doctrines that [filter out free-riders](https://www.jstor.org/stable/2138608) and help solve for the problem of credible commitment.

Switzerland has its of mountains and clans, which is why it’s so federated in the first place. Nonetheless, the decentered nature of Swiss institutions betrays a hidden, extended order, akin to a crystalline material whose special properties depend on atoms arranged into an unlikely, low entropy configuration.

Weakening the nation-state is thus not synonymous with promoting liberty. Rather, the proper synthesis between despotism and anarchy is captured in the classical concept of “order liberty.” [As Hayek notes](https://reason.com/2018/08/23/proposition-positive-liberty-isnt-true-l/#:~:text=As%20the%20economist,socially%20beneficial%20aims.%22) in _The Constitution of Liberty_,

> Not Locke, nor Hume, nor Smith, nor Burke, could ever have argued, as Bentham did, that ‘every law is an evil for every law is an infraction of liberty.’ Their argument was never a complete _laissez faire_ argument, which, as the very words show, is also part of the French rationalist tradition, and in its literal sense was never defended by any of the English classical economists.

Instead, Hayek argues the British classical liberals located liberty in “the evolution of ‘well-constructed institutions’ where the ‘rules and principles of contending interests and compromised advantages’ would be reconciled,” thereby channeling “individual efforts to socially beneficial aims.”

The liberal tradition is thus divided between utopian rationalists and pragmatic fallibilists. The former are descendants of the first Enlightenment, self-conscious of their fundamental autonomy and eager to redesign society from first principles. The latter adhere to what [Thomas Sowell](https://en.wikipedia.org/wiki/A_Conflict_of_Visions) called “the constrained vision.” They recognize that there are no ideal solutions, only second-best trade-offs, and have a Hayekian — [if not Hegelian](https://hamandcheese.medium.com/what-makes-me-hegelian-99d329dbd136) — appreciation for the ways in which Reason is socially mediated, rather than the wellspring of an individual ego.

## The use of intelligence in society

The Hayekian case for a strong but limited government is ultimately more epistemic than normative. Central planners suffer from a [knowledge problem](https://www.econlib.org/library/Essays/hykKnw.html). Government bureaucrats simply can’t match the parallel computation of the price system, even on their best day.

Yet as Tyler Cowen once pointed out, [governments are spontaneous orders too](https://web.archive.org/web/20070216102142/http://www.gmu.edu/jbc/Tyler/Spontaneous%20Order.pdf), and will thus expand or contract as the epistemic conditions change. The economists [Nicola Mastrorocco and Edoardo Teso](https://www.nber.org/papers/w31591#fromrss) recently tested this by looking at the role of monitoring technology in the evolution of U.S. federal bureaucracy from 1817 to 1905. By exploiting the staggered expansion of railroad and telegraph networks, they find that the growing ability of politicians to monitor state agents throughout the territory was an important driver of bureaucratic growth. As they put it,

> “The results suggest that high monitoring costs are associated with small, personalistic state organizations based on networks of trust; technological shocks lowering monitoring costs facilitate the emergence of modern bureaucratic states.”

In other words, monitoring costs are a core transaction cost influencing the equilibrium size and scope of modern governments. This is what James C. Scott meant by _[Seeing Like a State](https://en.wikipedia.org/wiki/Seeing_Like_a_State)_. To return to the metaphor from Part I, “Seeing like an _AI_ state” suggests our bureaucracies are about to get high resolution x-ray glasses.

Whether or not this leads to a bureaucratic expansion is another question. On the one hand, AI could enable regulators to devise rules with fractal specificity, micromanaging things that used to be illegible. On the other hand, the human and physical footprint of our bureaucracies could radically shrink, as even the finest-grained forms of compliance become automatic and thus invisible.

Nevertheless, the civil rights and liberties enshrined in our laws and Constitution will tend to shift the most extreme forms of monitoring into private entities. Suppose AI gives us 99.999% reliable lie detectors, thereby rendering “innocent until proven guilty” obsolete. Yet whether such evidence can be gathered in the first place will be up to the accused, as the Fifth Amendment protects against self-incrimination. Most private entities will be under no such obligation, however. And while it’s illegal for employers to compel a lie detector test under the Employee Polygraph Protection Act, this becomes unenforceable once a surreptitious recording of an employee’s face or body language suffices.

These inherent constraints on government, combined with AI’s much faster diffusion through the private sector, suggest a net _weakening_ of liberal governments relative to the rest of society. The rapid degeneracy of our legacy institutions could thus make a kind of high-tech anarchy suddenly viable, bootstrapped off the latent demand for social order and other public goods.

The moment governments realize that AI is a threat to their sovereignty, they will be tempted to clamp down in a totalitarian fashion. It’s up to liberal democracies to demonstrate institutional [co-evolution](https://en.wikipedia.org/wiki/Red_Queen_hypothesis) as a third-way between degenerate anarchy and an AI Leviathan. At a minimum, this will require embracing AI tooling within the machinery of government; painful concessions to the government functions that AI simply renders obsolete; and the dialectical construction of a new social contract — an AI ordered-liberty — that one hopes is far more Swiss than Pashtun.

Regardless of what path we take, one thing is certain: the U.S. government of 2040 will look as different to our contemporaries as the U.S. government of the 1940s must have looked to the men and women of the pre-industrial era.

[Part III](https://www.secondbest.ca/p/ai-and-leviathan-part-iii) will dig deeper into how this could all play out.

# AI and Leviathan: Part III

_A timeline of our techno-feudalist future_

**Author:** Samuel Hammond
**Published:** September 11, 2023
**URL:** https://www.secondbest.ca/p/ai-and-leviathan-part-iii

---

_Read [Part I](https://www.secondbest.ca/p/ai-and-leviathan-part-i) & [Part II](https://www.secondbest.ca/p/ai-and-leviathan-part-ii) here._

---

This series is about the potential near-term impact of Artificial Intelligence on our government and institutions.

My null hypothesis is that the democratization of powerful AI capabilities will be at least as destabilizing as the printing press. The printing press was also a mere information technology, and yet it led to civil wars and uprisings against the established order, and ultimately drove the consolidation of the modern nation-state.

Institutions are shaped by the transaction costs associated with bargaining and coordination, search and information, and monitoring and enforcement. While the internet impacted these cost structures to an extent, near-term AI will likely alter them dramatically, dislodging us from the basic institutional structures we inherited from the early-20th century.

[As the saying goes](https://www.poetryverse.com/robert-frost-poems/a-servant-to-servants#:~:text=He%20says%20the%20best%20way%20out%20is%20always%20through.%0AAnd%20I%20agree%20to%20that%2C%20or%20in%20so%20far%0AAs%20that%20I%20can%20see%20no%20way%20out%20but%20through), “there’s no way out but through,” but which through-path we take isn’t predetermined. Liberal democracy exists within a “[narrow corridor](https://www.amazon.com/Narrow-Corridor-States-Societies-Liberty/dp/0735224382)” between despotism and anarchy. In an ideal world, our political leaders would rapidly co-evolve our institutions with AI, striking a new balance between centralism and decentralization — a _constrained_ AI Leviathan. But that’s a vision for Part IV.

This essay, Part III, is about exploring the default path in which our government moves with the slowness and incompetence that we’ve grown accustom to.

## Whither Feudalism?

In the default scenario, the technology shock from AI will cause slower governments to either fragment or recede to a few core competencies, pushing the provision of various public goods (including security against AI misuse) into private hands. Call this the techno-feudalist timeline.

Take airports, which operate as mini, opt-in surveillance states complete with face scanners and awkward pat-downs. As a kind of company town, airports are essentially landlords. They’re largely staffed through outside contracts, and the food is always overpriced. And while most U.S. airports are owned by public entities, the wealthy country norm is to privatize them, as [privately owned airports](https://www.cato.org/tax-budget-bulletin/privatizing-us-airports) tend to be much nicer. Airports thus illustrate the many advantages of delegating security and other public goods to quasi-feudal organizations, as private companies:

1. aren’t obligated to respect your rights in the same way as governments;
2. are easier to trust due to reputation mechanisms, market competition, and explicit contracts that tie their hands; and
3. can use their “right to exclude” to create vertically integrated, technologically sophisticated user experiences.

Indeed, we voluntarily cede our rights to private organizations on a daily basis. We have nitpicky Home Owners Associations, casinos that track how much you drink, comedy clubs that confiscate your phone at the door, companies that make you sign an NDA before a lunch meeting, and employers that digitally monitor your productivity second-by-second. If you don’t like trading-off these natural liberties, you can always move, quit, or leave.

As AI democratizes capabilities with significant negative externalities, it will simultaneously unlock new institutional forms for dealing with those externalities. More and more of social and economic life will thus be driven behind walled-gardens. Different organizations will cater to different preferences by offering different bundles of rights and services, and compete on their ability to keep-up in the defensive-offensive AI arms-race. Examples include:

- Location-based bans on devices that can read private thoughts from facial expressions; extract keystrokes from background audio; cheat at games undetected, etc.
- Private schools that maximize student outcomes with the help of AI tutors and disciplinaries;
- Ultra personalized healthcare services that arbitrage around medical privacy laws to access genetic and biometric data;
- New forms of identity verification to mitigate the proliferation of deepfakes and catfish bots, a la Worldcoin;
- Monitoring and compliance platforms for underwriting goods and services in lieu of static regulatory frameworks;
- AI-based arbitration mechanisms for rapidly adjudicating disputes;
- Gated communities and privately owned “smart cities” that offer all of the above in addition to predictive policing, secured infrastructure, and a variety of AI-based amenities.

Versions of these already exist, but are either low-tech or highly concierge. As AI lowers costs and expands wealth, access to superior, privately-provided services will blossom and drive substitution away from legacy public goods. The cumulative effect will be to pick away at many basic government functions.

The rapid rise of ride-sharing apps like Uber and Lyft is an example of this dynamic in miniature. Prior to ride-sharing, every city regulated its own taxi service, quality was poor, and only the wealthy could afford “black car”-style options. Then the internet and mobile revolutions arrived and [dramatically reconfigured](https://www.adamsmith.org/blog/regulation-industry/uber-forms-of-governance) the structure of transaction costs. Suddenly riders and drivers could be connected directly, slashing search, information and bargaining frictions. Quality could be enforced through reputation and monitoring mechanisms rather than formal licensing regimes. And price discovery could be supplemented with machine learning to improve safety, reduce wait times, and optimize travel routes. Today, Uber is even [exploring the use of predictive AI](https://www.foxbusiness.com/technology/uber-seeks-patent-pre-match-riders-drivers-using-ai) to “pre-match” ride requests based on users’ contextual data.

[![](https://substackcdn.com/image/fetch/$s_!AFr_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbbbcd4d-3ec4-4a34-9dc0-2c18add7d338_1368x1058.png)](https://substackcdn.com/image/fetch/$s_!AFr_!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbbbcd4d-3ec4-4a34-9dc0-2c18add7d338_1368x1058.png)

Despite [often violent resistance](https://www.bbc.com/news/world-europe-33267581), the benefits from ride-sharing ultimately forced a microcosmic regime change in cities worldwide. Traditional taxi services still exist, but often only because of latent regulatory privileges, like special access to the airport. Regardless, in markets like New York City, the [percentage of trips](https://citymonitor.ai/transport/uber-lyft-rides-during-coronavirus-pandemic-taxi-data-5232) done by taxis flipped from ~90% to ~10% in just five years, shifting the market’s governance from a public commission to competing private platforms with inbuilt social credit scores. The next step is Level 5 self-driving. Robotaxis are already on the road in several jurisdictions, and will surely be equipped with intelligent monitoring systems to keep riders’ [on their best behavior](https://sfstandard.com/2023/08/11/san-francisco-robotaxi-cruise-debauchery/).

As AIs reach human-level capabilities and beyond, the organizational economies that drove centralized forms of regulation will collapse in other areas of life as well. In some ways, this process will look like the 19th and 20th centuries running in reverse. Communities were once much more gated, for instance, if only by distance. Local school houses were the norm. Social insurance was based in [mutual aid](https://www.secondbest.ca/p/the-most-american-religion-mormon). Fake news was commonplace, so information flowed through trusted networks. Law enforcement was sparse and supplemented by private security. And regulation, to the extent it existed, was often [supplied privately](https://www.cato-unbound.org/2015/10/05/edward-peter-stringham/how-private-governance-made-modern-world-possible/) through exclusive clubs and associations.

## The Default Future

To see how we get from here to there, let’s extrapolate AI progress on its current trajectory under the default scenario where the U.S. government evolves minimally or not at all. Predictions are hard, especially about the future, but informed speculation is better than nothing, if only for scenario planning.

#### 2024 - 2027

Based on current trends, in a few years the [vast majority](https://futurism.com/the-byte/experts-90-online-content-ai-generated) of content on the internet becomes synthetic. d narratives breakdown and the public becomes some mixed of confused, panicked and entertained by the pace of change. Between the twilight of copyright and the disruption to centralized content distribution, traditional news media and Hollywood are the first to Jihad against AI, like the techlash of the 2010s turned up to eleven.

LLMs and multimodal models start hitting enterprise, automating substantial amounts of make-work, data collection, and regulatory compliance. By nature, the technology easily integrates into legacy processes, at least compared to the bespoke automations companies were used to buying from the IBMs of the world. The economic impact resembles the downsizing wave of the late-1990s.

Several weakly agentic AIs leak onto the internet, infecting computers with intelligent malware that reminds security experts of the famous [Morris worm](https://en.wikipedia.org/wiki/Morris_worm). While they aren’t about to destroy the world, the internet starts to balkanize as the value of AI and the proliferation of cyberattacks spurs a global rush to nationalize compute and telecommunications infrastructure. Open platforms begin to gate access to counter against bots, and online discussion shifts hard into secure channels, a la Signal or Telegram, with zero-knowledge protocols for verifying users as human.

Science starts accelerating, but society as whole feels infinitely less legible, as if hidden behind [digital hills](https://en.wikipedia.org/wiki/The_Art_of_Not_Being_Governed).

#### 2028 - 2031

Based on the [Direct Approach forecast](https://epochai.org/blog/direct-approach-interactive-model) produced by the researchers at EpochAI, it becomes possible to brute-force an AGI that is indistinguishable from humans on most tasks by 2029. At first, these gigantic models are grossly inefficient, so there is still demand for narrower, distilled forms of AI that require thoughtful integrations. Yet as the inference cost from truly general models comes down, unified AI systems are able to simply shadow human workers and learn to emulate their workflow in-context, causing implementation frictions to collapse.

[![](https://substackcdn.com/image/fetch/$s_!ABDo!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19b1da38-76eb-41e5-aa79-ebc199d89182_1051x829.png)](https://substackcdn.com/image/fetch/$s_!ABDo!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19b1da38-76eb-41e5-aa79-ebc199d89182_1051x829.png)

Job losses in cognitive sectors ramp up. Many businesses go the way of Blockbuster, but most knowledge sectors undergo an accelerated version of what the internet did to media and publishing. That is, rather than vanish overnight, a subset of incumbents consolidate in the background of rolling bankruptcies, the rise of new business models, last-ditch efforts at regulatory capture, and a long-tail of amateur creators.

By the early 2030s, the knowledge jobs that remain are highly bimodal. A subset of entrepreneurs are highly remunerated, while the best paid jobs involve co-piloting large teams of AIs. This looks a hypertrophied version of what the internet did to the [income distribution of lawyers](https://peterturchin.com/bimodal-lawyers-how-extreme-competition-breeds-extreme-inequality/), only extended to many other sectors.

Most other knowledge jobs either feature intense monitoring and [performance management](https://sloanreview.mit.edu/article/ai-is-helping-companies-redefine-not-just-improve-performance/); are rooted in personal relationships and other sources of economic rent; or are intrinsically identity or celebrity driven, just as “Youtuber” and “Twitch streamer” are today. Regardless, cognitive labor markets are now increasingly characterized by highly skewed returns and an often explicit reliance on [patronage](https://backlinko.com/patreon-users). The division of cognitive labor matters much less than it used to, and so the extent of the market — and thus the need for common legal and regulatory frameworks — begins to contract.

[![](https://substackcdn.com/image/fetch/$s_!mXz9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84695aa7-2b60-4b07-9401-6e8d4dd1fec8_1188x468.png)](https://substackcdn.com/image/fetch/$s_!mXz9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84695aa7-2b60-4b07-9401-6e8d4dd1fec8_1188x468.png)

[Bimodal Lawyers](https://peterturchin.com/bimodal-lawyers-how-extreme-competition-breeds-extreme-inequality/) - Peter Turchin (2013)

While the stock market as a whole is booming, the Great Repricing is well underway — a kind of Napster moment for everything. Many asset prices go to zero while a handful of companies blow past trillion dollar valuations. The limiting factor is energy and capital. Most compute infrastructure now goes to inference, and new datacenters can’t be built fast enough.

Congress is in a panic. Member offices are flooded by emails from AI lobbyists and robo-callers that affect their constituents’ local dialect. Every lawmaker has a special interest for whom the AI wave is existential, spurring a rash of ad hoc and reactionary proposals that go nowhere. Overtime, however, a broader reshuffling of public choice constraints is afoot, eventually unlocking a flurry of reforms on issues that used to be stalemated, but which still aren’t radical enough.

By now, the White House and Congress have taken steps to regulate frontier AI companies. While the most powerful models must undergo safety evaluations that assess for bias and their vulnerability to jailbreaks, the classic alignment problem turns out to get easier with scale, as the biggest models prove eminently controllable. Nor does AGI immediately cause a superintelligence hard take-off, as data and compute bottlenecks still limit the amount of [cross-entropy](https://machinelearningmastery.com/cross-entropy-for-machine-learning/#:~:text=the%20Same%20Thing-,What%20Is%20Cross%2DEntropy%3F,encode%20and%20transmit%20an%20event.) that bigger models can feasibly harvest.

While the open source ecosystem is thriving, the gap between open source and proprietary models has widened, in part because of the logarithmic nature of neural scaling laws, and in part because regulatory and liability risk have pushed the most ambitious open source efforts underground. Attention thus shifts to the broader proliferation risk from powerful AI agents as the compute requirements to train and run them trickle down.

#### 2032 - 2035

Multi-billion dollar startups are now created by as few as 3 people designing clever workflows around teams of interacting AIs. AIs don’t shirk and work diligently 24/7, making even a single human in the loop a potential bottleneck. As agency and monitoring costs collapse, [AI-native organizations](https://blog.mutable.ai/p/the-ai-organization-part-i) begin to interface with each other at inference speeds through a nexus of _genuinely_ smart contracts, blurring the boundaries between one AI firm and the next. The owners of the AI companies with the deepest moats start to resemble _[The Power Elite](https://en.wikipedia.org/wiki/The_Power_Elite)_ described by sociologist C. Wright Mills — the horizontal network of military, economic and political elites that sat atop the corporate giants of the mid-20th century.

[![](https://substackcdn.com/image/fetch/$s_!y-VI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb771ae7-7546-4e9b-875a-6a7d69e6dae0_818x736.png)](https://substackcdn.com/image/fetch/$s_!y-VI!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb771ae7-7546-4e9b-875a-6a7d69e6dae0_818x736.png)

[The Decadal Plan for Semiconductors](https://www.src.org/about/decadal-plan/), SIA (2020)

The institutional infrastructure created in the New Deal and Great Society eras begins to crack. Aggregate economic activity is taking off, but regulatory agencies simply lack the capacity to track it all, and in some cases suffer de facto [Denial of Service](https://www.secondbest.ca/p/before-the-flood) attacks. Indeed, sensor technologies now generate more than 10^20 bits of data per second, [surpassing the collective sensing throughput of humanity](https://www.semiconductors.org/wp-content/uploads/2020/10/Decadal-Plan_Interim-Report.pdf). This demands a paradigm shift in the way governments extract relevant information, but the technical debt from generations of process accumulation and [kludgeocracy](https://www.nationalaffairs.com/publications/detail/kludgeocracy-in-america) is a binding constraint. While high-trust countries with ministerial systems embrace sweeping civil service reforms, the analogous reforms in the U.S. are caught-up in interagency process, judicial review, the Senate filibuster, procurement and talent acquisition issues, and protests from public sector unions.

An explosion in lifesaving drugs and medical devices are stuck in the FDA pipeline, spurring gray markets and state-level “right to try” laws that end-run the approval process. Gated industries like medicine and law try in vain to maintain their regulatory privileges, but are ultimately pushed to embrace AI and cannibalize their older business models. Enforcement agencies, from the NLRB to the FTC, can now only enforce a sliver of their increasingly anachronistic jurisdictions.

[![](https://substackcdn.com/image/fetch/$s_!rv01!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bfaccd5-15cd-4078-8893-aefca041c8ea_1202x1240.png)](https://substackcdn.com/image/fetch/$s_!rv01!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bfaccd5-15cd-4078-8893-aefca041c8ea_1202x1240.png)

[GAO-23-106020](https://www.gao.gov/products/gao-23-106020) (2023)

Tax revenues decline and the IRS’s audit ratio collapses as income shifts from labor to capital and AI tax accountants work to complexify everyone’s liability, such as through convoluted [partnerships](https://www.gao.gov/products/gao-23-106020). The court system is overwhelmed by an explosion in AI-assisted lawsuits and is forced to triage disputes based on type. This pushes more and more civil and commercial law into private arbitration, as [AI judges](https://www.taipeitimes.com/News/front/archives/2023/08/27/2003805341) can digest terabytes of evidence to render provably neutral decisions in an afternoon.

Private forms of regulation begin to emerge. While the likes of the USDA, OSHA, and CPSC are still sending humans to inspect commercial farms, do workplace visits, and issue product recalls, their de facto regulatory aperture is increasingly narrow. Consumers begin to put more trust into AI underwriters and [multi-sided platforms](https://www.hbs.edu/faculty/Pages/item.aspx?num=35339) that assure food, workplace and product safety through automated compliance and reputation systems, eliminating the problem of [asymmetric information](https://www.cato-unbound.org/2015/04/06/alex-tabarrok-tyler-cowen/end-asymmetric-information/) outright.

Many other federal responsibilities are simply rendered obsolete. Now that most of the cars on the road are fully autonomous, for instance, the National Highway Traffic Safety Administration feels lost for purpose. The democratization of autonomous sensors and commercial satellite networks has even displaced the value of the National Weather Service. The response to [natural disasters](https://www.nbcnews.com/news/us-news/survivors-maui-fires-set-aid-network-trust-government-falters-rcna100041) is now primarily mediated by [private initiatives](https://www.mercatus.org/students/economic-insights/expert-commentary/community-resilience-through-mesh-networking), including through parallel early warning systems.

#### 2036 - 2039

[Strong AGI](https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/) comes for motor control and robotics. Just as LLMs supplanted a dozen distinct subdisciplines in natural language processing, general purpose motor-action feedback models supplant the dozens of ad hoc planning and control algorithms used in today’s robotics. That is, a pre-trained model can now plug into robots with arbitrary shapes, sensors and actuators, and find an optimal control loop with a bit of play-like practice.

General purpose robots begin to be manufactured at scale, driving down costs. The dynamics that played out in the knowledge sector thus begin to affect goods production and manual forms of labor. Service innovation was already pushing GDP growth above 5%, but now physical productivity really takes off, although in a way that lingering bottlenecks make highly differential. Labor intensive human services, such as nursing, education and policing, suffer a severe version of [Baumol’s cost disease](https://www.niskanencenter.org/cost-disease-socialism-how-subsidizing-costs-while-restricting-supply-drives-americas-fiscal-imbalance/). State and local governments are thus forced to either absorb accelerating labor costs or embrace AI alternatives.

Given the highly uneven quality of local governance, more people begin opting-out of municipal services. Cheap and customizable AI tutors spur a mass exodus from the public education system in favor of high-tech boarding schools and home- and community-based education collectives. Neighborhoods purchase their own drones and use the equivalent of hundreds of doorbell cameras with facial recognition to form their own private surveillance network. Package thieves and burglars don’t bother enter these neighborhoods, as local residents receive push alerts the moment a street camera recognizes the gait of a crook known to a proprietary database.

Pockets of [state capacity](https://www.secondbest.ca/p/three-motivations-for-state-capacity) still exist but in a way that is alarmingly derivative on the private sector. While the U.S. government of 1940-70s did the Manhattan and Apollo Projects inhouse, such initiatives are now outsourced to the likes of Amazon, Google, Microsoft, Palantir and SpaceX. The U.S. government couldn’t even build its own cloud infrastructure if it wanted to. In the face of system failure, more and more administrative functions are thus offloaded onto private providers, turning the federal government into a glorified nexus of competitive contracts.

#### 2040 and beyond

Moore’s Law hits the [Landauer limit](https://semiengineering.com/running-out-of-energy/), but is carried forward thanks to advancements in parallel computing and [low energy memristors](https://spectrum.ieee.org/memristor-devices-ai). Exascale computers are now commonplace, causing the AI safety regime from the decade prior to break down. In practice, however, the permissions required to deploy new AI systems simply shifts from governments to private infrastructure providers.

The World Wide Web is a wild west of deepfakes and intelligent malware, reminiscent of the early days when one mis-click would unleash a flood of popups and .exe downloads. This has forced the development of new protocols, certificate authorities, and access lists that use AI to monitor network traffic for security threats and deny routing to unvetted users and algorithms. Telecom providers contract directly with neighborhoods and private cities, using geofencing and network firewalls to strictly control the traffic in and out of each local area network. The richer of these neighborhoods even have their own GPU clusters to insure against network outages and help [heat the community pool](https://www.bbc.com/news/technology-64939558).

[![](https://substackcdn.com/image/fetch/$s_!cM6j!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F236d5d2f-f72a-4f8e-82c1-7b8ea0a371fe_1024x1024.png)](https://substackcdn.com/image/fetch/$s_!cM6j!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F236d5d2f-f72a-4f8e-82c1-7b8ea0a371fe_1024x1024.png)

There are now individuals as powerful as today’s large corporation, and large corporations as powerful as today’s nation-states. Many city governments thus abandon their historic charters and reincorporate as Singapore-esque company towns. The corporate structure provides a means for cities to pool investors’ capital and finance public goods through land rents, the most important of which is security. AVs entering city limits must pass through checkpoints that automatically scan for contraband and log their passenger’s identity; waste water is continuously monitored for genetically engineered pathogens; and EM pulse guns scan the airspace for unauthorized drone swarms. Unless you’re rich enough to afford private security, few venture beyond city limits except for travel between secure zones. The agglomeration externalities to AI are simply too great, as rural holdouts run the risk of being ransacked by roving militias or the agents of the synthetic drug cartels.

It’s an increasingly post-scarcity world in everything except land and capital. Yet between fusion, solar and advanced geothermal, energy is not only cheap and abundant but also locally generated. Paired with robotic labor, this enables a radical re-localization of supply chains, putting globalization in reverse.

Countries now divide into the three broad categories: Chinese-style police state / Gulf-style monarchy; anarchic failed state; or high-tech open society with an AI-fortified e-governments on the [Estonia model](https://readplaintext.com/disrupting-bureaucracy-fa611d04f956). The world map is thus redrawn as strong states use AI to conquer their failed neighbors and reestablish regional security.

America would be a failed state but for its archipelago of micro-jurisdictions with varying degrees of flourishing. The U.S. military thus focuses almost exclusively on internal security threats, from the growing number of sovereignty movements, to the anarchic conditions of large swaths of the country. The situation is unstable, however, as AI has resurrected dead ideologies like communism and cybernetic fascism, devolving national politics into a referendum on competing utopian movements.

It’s almost 2045, eerily close to Ray Kurzweil’s date for the technological singularity. In the background of all this political instability, research and development toward superintelligence has continued from the safety and comfort of [Solano County](https://californiaforever.com/) — the free city of choice for ML engineers and other post-AGI trillionaires.

The city is home to a fusion-powered supercluster with billions of times more computational power than every human brain combined. It just completed its first big training run and the new model is ready to be tested. The engineers have read _[The Sequences](https://www.lesswrong.com/tag/sequences)_ and know the danger, but their pride, curiosity and [Benthamite expected value calculations](https://conversationswithtyler.com/episodes/sam-bankman-fried/#:~:text=Okay%2C%20but%20let%E2%80%99s%20say%20there%E2%80%99s%20a%20game%3A%2051%20percent%2C%20you%20double%20the%20Earth%20out%20somewhere%20else%3B%2049%20percent%2C%20it%20all%20disappears.%20Would%20you%20play%20that%20game%3F%20And%20would%20you%20keep%20on%20playing%20that%2C%20double%20or%20nothing%3F) all scream “turn it on!”

Besides, who’s going to stop them?

And that is why [the order of AI risks matters](https://www.secondbest.ca/p/the-order-of-ai-risks-matters). Even if the intermediate stages of AI don’t kill us all, they may indirectly affect x-risk by upending the very institutions we'll need during the stage that does.
