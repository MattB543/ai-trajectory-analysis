# High-Level Summary

**Original Document:** full_doc.md

**Generated:** 2025-10-12 19:29:32

---

This report argues that advanced AI could enable a small group—or even a single individual—to seize state power, including in established democracies, by creating novel dynamics that greatly raise coup risk: AI workforces could be engineered to have singular loyalty to particular leaders, systems could be made secretly loyal in ways that are very hard to detect, and frontier capabilities (weapons design, strategic planning, persuasion, cyber-offence and rapid AI R&D) could become concentrated in the hands of a few insiders; these risks are amplified by likely trends toward fewer frontier projects, automated AI development, and military or government deployment of autonomous systems. The paper maps concrete coup pathways—novel military-AI routes (flawed command structures, secretly loyal military systems, hacking of common-vulnerability AI fleets, or a rapid secret private build‑out) and enhanced conventional backsliding and executive coups aided by superhuman strategy and influence tools—and explains how interactions among singular loyalties, secret loyalties and exclusive access make success more plausible. To reduce this threat, the authors recommend urgent, coordinated mitigations: developers should codify prohibitions on coup‑enabling uses in model specs, terms of service and procurement contracts; implement robust technical enforcement (strong guardrails, thorough alignment audits for hidden objectives, high-grade infosecurity resistant even to senior insiders, logging and system‑level stress‑testing); and empower multiple actors via transparency, distributed decision‑making, shared access to sensitive capabilities, multi‑provider procurement for military AI, whistleblower protections and coup‑proof governance (especially for any centralized national project). Governments should require and oversee these measures, build in legislative and judicial checks, and avoid or tightly constrain centralisation of frontier AI without multi‑party oversight; while no mitigation is perfect and some could be rolled back by determined actors, the report argues that many measures would be hard to remove once established and that building broad consensus now can substantially reduce the risk—making prevention of AI‑enabled coups a priority for defenders of democracy.